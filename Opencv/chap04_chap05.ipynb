{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# chap4 에지와 영역\n",
        "\n",
        "#### 에지 \n",
        "물체 경계에 위치한 점 \n",
        "- 에지 검출 : 에지에 해당 화소 찾기\n",
        "- 에지 향상 : 에지 더 잘보이도록 하기 위해 에지와 배경 간의 대비 증가\n",
        "- 에지 추적 : 에지 따라가기\n",
        "\n",
        "- 에지를 완벽하게 검출해 물체의 경계를 폐곡선으로 따낼 수 있다면 분할 문제 해결\n",
        "- 특성이 크게 다른 화소에 집중하는 방식\n",
        "\n",
        "-> 물체의 위치 모양 크기 에 대한 정보 찾기 가능\n",
        "\n",
        "#### 영역\n",
        "특성이 비슷한 화소를 묶는 방식"
      ],
      "metadata": {
        "id": "7diBQjv4KEJd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "에지 검출 알고리즘 : 물체 내부는 명암이 서서히 변하고 경계는 급격히 변하는 특성 활용\n",
        "\n",
        "### 4.1.1 영상의 미분\n",
        "미분 : 변수의 x 값이 미세하게 증가했을 때 함수 변화량 측정, 에지 추출 방법\n",
        "\n",
        "* 영상을 (x, y) 변수의 함수로 간주했을 때, 이 함수의 1차 미분(1st derivative) 값이 크게 나타나는 부분을 검출\n",
        "\n",
        "디지털 영상 미분\n",
        "- 미분은 기본적으로 연속적인 공간에서 적용, but 영상은 연속공간이 아닌 이산 공간이기에 근사화한 것으로 적용\n",
        "- 영상 f에 미분 적용해 f'\n",
        "- 필터 u(에지 연산자)로 컨볼루션하여 구현\n",
        "- 명암을 미분해 튀어나온 부분이 에지\n",
        "\n",
        "### 4.1.2 에지 연산자\n",
        "- 명암 변화 x = 0\n",
        "- 명암 변화 o = 3\n",
        "\n",
        "컨볼루션의 값은 f 원래 영상의 부호를 의미한다 !?\n",
        "\n",
        "물체 경계를 지나면서 명암값이 커지면 미분값 양수, 작아지면 음수\n",
        "\n",
        "\n",
        "램프에지 : 계단 모양이 아닌, 명암이 몇화소에 걸쳐 변화, 정확한 에지의 위치 찾기 어려움\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vDC6Jh_hJ0i-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "rOt3lRN1I-NO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ycbtcQG2I-Gi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aE7pQfKXFLC-"
      },
      "outputs": [],
      "source": [
        "# 4-1 에지 검출\n",
        "import cv2 as cv\n",
        "\n",
        "img=cv.imread('soccer.jpg')\n",
        "gray=cv.cvtColor(img,cv.COLOR_BGR2GRAY) # 명암으로 변화\n",
        "\n",
        "# 소벨 연산자 적용\n",
        "grad_x=cv.Sobel(gray,cv.CV_32F,1,0,ksize=3)\t# 결과 영상 32비트 실수 맵 저장, (1,0) x 방향 연산자, 3*3 크기 사용\n",
        "grad_y=cv.Sobel(gray,cv.CV_32F,0,1,ksize=3) # y 방향 연산자\n",
        "\n",
        "# 음수가 포함된 맵에 절대값을 취해 양수 영상으로 변환\n",
        "sobel_x=cv.convertScaleAbs(grad_x)\t# convertScaleAbs : 부호없는 8비트형 맵을 형성해 크기가 0보다 작으면 0, 255넘으면 255\n",
        "sobel_y=cv.convertScaleAbs(grad_y)\n",
        "\n",
        "# 에지 강도 계산\n",
        "edge_strength=cv.addWeighted(sobel_x,0.5,sobel_y,0.5,0)\t# sobel_x * 0.5 + sobel_y * 0 + 0\n",
        "# sobel_x 와 sobel_y 가 같은 데이터 형이면 결과영상 같은 데이터 형\n",
        "# 다른 데이터 형이면 결과영상 에러 \n",
        "\n",
        "# 결과영상 윈도우 디스플레이\n",
        "cv.imshow('Original',gray)\n",
        "cv.imshow('sobelx',sobel_x)\n",
        "cv.imshow('sobely',sobel_y)\n",
        "cv.imshow('edge strength',edge_strength)\n",
        "\n",
        "cv.waitKey()\n",
        "cv.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4-2 캐니 에지\n",
        "# import cv2 as cv\n",
        "\n",
        "img=cv.imread('soccer.jpg')\t# 영상 읽기\n",
        "gray=cv.cvtColor(img,cv.COLOR_BGR2GRAY)\n",
        "\n",
        "\n",
        "canny1=cv.Canny(gray,50,150)\t# Tlow=50, Thigh=150으로 설정\n",
        "canny2=cv.Canny(gray,100,200)\t# Tlow=100, Thigh=200으로 설정\n",
        "\n",
        "\n",
        "cv.imshow('Original',gray)\n",
        "cv.imshow('Canny1',canny1) # 에지 강도가 작은 화소도 추적 가능하나 잡음 발생\n",
        "cv.imshow('Canny2',canny2) # 임계값 높으면 에지강도가 큰 화소만 추적해 더 작은 에지 발생\n",
        "\n",
        "\n",
        "cv.waitKey()\n",
        "cv.destroyAllWindows()"
      ],
      "metadata": {
        "id": "saB0boTCFeqr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4-3 직선 검출\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "img=cv.imread('soccer.jpg')\t # 영상 읽기\n",
        "gray=cv.cvtColor(img,cv.COLOR_BGR2GRAY)\n",
        "canny=cv.Canny(gray,100,200) \n",
        "\n",
        "\n",
        "contour,hierarchy=cv.findContours(canny,cv.RETR_LIST,cv.CHAIN_APPROX_NONE) # 경계선 정보 검출\n",
        "\n",
        "\n",
        "lcontour=[]   \n",
        "for i in range(len(contour)):\n",
        "    if contour[i].shape[0]>100:\t# 길이가 100보다 크면 \n",
        "        lcontour.append(contour[i])\n",
        "  \n",
        "# 외곽선 그리기\n",
        "cv.drawContours(img,lcontour,-1,(0,255,0),3)\n",
        "             \n",
        "\n",
        "cv.imshow('Original with contours',img)    \n",
        "cv.imshow('Canny',canny)    \n",
        "\n",
        "\n",
        "cv.waitKey()\n",
        "cv.destroyAllWindows()"
      ],
      "metadata": {
        "id": "TQRaIk5UFene"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4-3 직선검출\n",
        "import cv2 as cv \n",
        "\n",
        "\n",
        "img=cv.imread('apples.jpg')\n",
        "gray=cv.cvtColor(img,cv.COLOR_BGR2GRAY)\n",
        "\n",
        "apples=cv.HoughCircles(gray,cv.HOUGH_GRADIENT,1,200,param1=150,param2=20,minRadius=50,maxRadius=120) # 원 검출 허프변환\n",
        "\n",
        "# 원의 중심, 반지름 정보 이용해 원래 영상에 원 그려넣기\n",
        "for i in apples[0]: \n",
        "    cv.circle(img,(int(i[0]),int(i[1])),int(i[2]),(255,0,0),2)\n",
        "\n",
        "\n",
        "cv.imshow('Apple detection',img)  \n",
        "\n",
        "\n",
        "cv.waitKey()\n",
        "cv.destroyAllWindows()"
      ],
      "metadata": {
        "id": "jFW9TbvNFejE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-image"
      ],
      "metadata": {
        "id": "xQqdlqPqlJ16"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4-4\n",
        "import skimage # 입력 영상을 슈퍼화소로 분할하기에 slic 함수가 사용하기 편리\n",
        "import numpy as np\n",
        "import cv2 as cv\n",
        "\n",
        "\n",
        "img = skimage.data.coffee() # 내부 coffee 영상 읽어 객체 저장\n",
        "cv.imshow('Coffee image',cv.cvtColor(img,cv.COLOR_RGB2BGR))\n",
        "\n",
        "\n",
        "slic1 = skimage.segmentation.slic(img,compactness=20,n_segments=600) # 슈퍼 화소 분할 수행\n",
        "sp_img1 = skimage.segmentation.mark_boundaries(img,slic1) # 객체 분할 정보 img 영상에 표시, 결과를 sp_img1 객체에 저장\n",
        "sp_img1 = np.uint8(sp_img1*255.0) # 표현 type을 0-255사이로 변환하고 unit8형으로 변환\n",
        "\n",
        "# 위와 동일, 파라미터만 수정\n",
        "slic2=skimage.segmentation.slic(img,compactness=40,n_segments=600) \n",
        "sp_img2=skimage.segmentation.mark_boundaries(img,slic2)\n",
        "sp_img2=np.uint8(sp_img2*255.0)\n",
        "\n",
        "\n",
        "cv.imshow('Super pixels (compact 20)',cv.cvtColor(sp_img1,cv.COLOR_RGB2BGR))\n",
        "cv.imshow('Super pixels (compact 40)',cv.cvtColor(sp_img2,cv.COLOR_RGB2BGR))\n",
        "\n",
        "\n",
        "cv.waitKey()\n",
        "cv.destroyAllWindows()"
      ],
      "metadata": {
        "id": "lkdo0d1FFegr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import skimage\n",
        "import numpy as np\n",
        "import cv2 as cv\n",
        "import time\n",
        "\n",
        "\n",
        "coffee=skimage.data.coffee()\n",
        "\n",
        "\n",
        "start=time.time() # 분할하는 데 걸리는 시간 측정\n",
        "slic=skimage.segmentation.slic(coffee,compactness=20,n_segments=600,start_label=1) # 슈퍼화소로 분할\n",
        "\n",
        "g=skimage.future.graph.rag_mean_color(coffee,slic,mode='similarity') \n",
        "ncut=skimage.future.graph.cut_normalized(slic,g)\t# 정규화 절단\n",
        "print(coffee.shape,' Coffee 영상을 분할하는데 ',time.time()-start,'초 소요') # 시간 측정\n",
        "\n",
        "\n",
        "marking=skimage.segmentation.mark_boundaries(coffee,ncut)\n",
        "ncut_coffee=np.uint8(marking*255.0)\n",
        "\n",
        "\n",
        "cv.imshow('Normalized cut',cv.cvtColor(ncut_coffee,cv.COLOR_RGB2BGR)) \n",
        "\n",
        "\n",
        "cv.waitKey()\n",
        "cv.destroyAllWindows()"
      ],
      "metadata": {
        "id": "SCMAwDX4Feee"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2 as cv \n",
        "import numpy as np\n",
        "\n",
        "\n",
        "img=cv.imread('soccer.jpg')\t# 영상 읽기\n",
        "img_show=np.copy(img)\t\t# 붓 칠을 디스플레이할 목적의 영상\n",
        "\n",
        "# 사용자가 붓칠에 따라 물체인지 배경인지에 대한 정보를 기록할 배열 생성\n",
        "mask=np.zeros((img.shape[0],img.shape[1]),np.uint8) \n",
        "mask[:,:]=cv.GC_PR_BGD\t\t# 모든 화소를 배경일 것 같음으로 초기화\n",
        "\n",
        "\n",
        "BrushSiz=9\t\t\t\t# 붓의 크기\n",
        "LColor,RColor=(255,0,0),(0,0,255)\t# 파란색(물체)과 빨간색(배경)\n",
        "\n",
        "\n",
        "def painting(event,x,y,flags,param):\n",
        "    if event==cv.EVENT_LBUTTONDOWN:   \n",
        "        cv.circle(img_show,(x,y),BrushSiz,LColor,-1)\t# 왼쪽 버튼 클릭하면 파란색\n",
        "        cv.circle(mask,(x,y),BrushSiz,cv.GC_FGD,-1)\n",
        "\n",
        "    elif event==cv.EVENT_RBUTTONDOWN: \n",
        "        cv.circle(img_show,(x,y),BrushSiz,RColor,-1)\t# 오른쪽 버튼 클릭하면 빨간색\n",
        "        cv.circle(mask,(x,y),BrushSiz,cv.GC_BGD,-1)\n",
        "\n",
        "    elif event==cv.EVENT_MOUSEMOVE and flags==cv.EVENT_FLAG_LBUTTON:\n",
        "        cv.circle(img_show,(x,y),BrushSiz,LColor,-1)# 왼쪽 버튼 클릭하고 이동하면 파란색\n",
        "        cv.circle(mask,(x,y),BrushSiz,cv.GC_FGD,-1)\n",
        "\n",
        "    elif event==cv.EVENT_MOUSEMOVE and flags==cv.EVENT_FLAG_RBUTTON:\n",
        "        cv.circle(img_show,(x,y),BrushSiz,RColor,-1)\t# 오른쪽 버튼 클릭하고 이동하면 빨간색\n",
        "        cv.circle(mask,(x,y),BrushSiz,cv.GC_BGD,-1)\n",
        "\n",
        "    cv.imshow('Painting',img_show)\n",
        "\n",
        "    \n",
        "cv.namedWindow('Painting')\n",
        "cv.setMouseCallback('Painting',painting)\n",
        "\n",
        "\n",
        "while(True):\t\t\t\t# 붓 칠을 끝내려면 'q' 키를 누름\n",
        "    if cv.waitKey(1)==ord('q'): \n",
        "        break\n",
        "\n",
        "# ----------------- GrabCut 적용하는 코드 -----------------\n",
        "background=np.zeros((1,65),np.float64)\t# 배경 히스토그램 0으로 초기화\n",
        "foreground=np.zeros((1,65),np.float64)\t# 물체 히스토그램 0으로 초기화\n",
        "\n",
        "# 실제 분할시도\n",
        "cv.grabCut(img,mask,None,background,foreground,5,cv.GC_INIT_WITH_MASK)\n",
        "mask2=np.where((mask==cv.GC_BGD)|(mask==cv.GC_PR_BGD),0,1).astype('uint8')\n",
        "grab=img*mask2[:,:,np.newaxis]\n",
        "cv.imshow('Grab cut image',grab)  \n",
        "\n",
        "\n",
        "cv.waitKey()\n",
        "cv.destroyAllWindows()"
      ],
      "metadata": {
        "id": "om7OvLDcFeb5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import skimage\n",
        "import numpy as np\n",
        "import cv2 as cv\n",
        "\n",
        "\n",
        "orig=skimage.data.horse()\n",
        "img=255-np.uint8(orig)*255 # 말 영역은 255, 배경은 0\n",
        "cv.imshow('Horse',img)\n",
        "\n",
        "# 물체 경계선 추출\n",
        "contours,hierarchy=cv.findContours(img,cv.RETR_EXTERNAL,cv.CHAIN_APPROX_NONE)\n",
        "\n",
        "\n",
        "img2=cv.cvtColor(img,cv.COLOR_GRAY2BGR)\t\t# 컬러 디스플레이용 영상\n",
        "cv.drawContours(img2,contours,-1,(255,0,255),2) # 경계선 표시 (영상,경계선,경계선 모두 표시, 색깔, 선 두께)\n",
        "cv.imshow('Horse with contour',img2)\n",
        "\n",
        "\n",
        "contour=contours[0]\n",
        "\n",
        "\n",
        "m=cv.moments(contour)\t\t\t\t# 모멘트 추출해 저장  \n",
        "area=cv.contourArea(contour) # 경계선으로 둘러싸인 영역의 면적 계산\n",
        "cx,cy=m['m10']/m['m00'],m['m01']/m['m00'] # 중점\n",
        "perimeter=cv.arcLength(contour,True) # 둘레의 길이 계산\n",
        "roundness=(4.0*np.pi*area)/(perimeter*perimeter) # 둥근정도\n",
        "print('면적=',area,'\\n중점=(',cx,',',cy,')','\\n둘레=',perimeter,'\\n둥근 정도=',roundness)\n",
        "\n",
        "\n",
        "\n",
        "img3=cv.cvtColor(img,cv.COLOR_GRAY2BGR)\t\t# 컬러 디스플레이용 영상\n",
        "\n",
        "\n",
        "\n",
        "contour_approx=cv.approxPolyDP(contour,8,True)\t# 직선 근사\n",
        "cv.drawContours(img3,[contour_approx],-1,(0,255,0),2)\n",
        "\n",
        "\n",
        "hull=cv.convexHull(contour)\t\t\t# 볼록 헐\n",
        "hull=hull.reshape(1,hull.shape[0],hull.shape[2])\n",
        "cv.drawContours(img3,hull,-1,(0,0,255),2)\n",
        "\n",
        "\n",
        "cv.imshow('Horse with line segments and convex hull',img3)\n",
        "\n",
        "\n",
        "cv.waitKey()\n",
        "cv.destroyAllWindows()"
      ],
      "metadata": {
        "id": "tTYlcOlDFeXf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2 as cv\n",
        "import numpy as np\n",
        "\n",
        "img=np.array([[0,0,0,0,0,0,0,0,0,0],\n",
        "              [0,0,0,0,0,0,0,0,0,0],\n",
        "              [0,0,0,1,0,0,0,0,0,0],\n",
        "              [0,0,0,1,1,0,0,0,0,0],\n",
        "              [0,0,0,1,1,1,0,0,0,0],\n",
        "              [0,0,0,1,1,1,1,0,0,0],\n",
        "              [0,0,0,1,1,1,1,1,0,0],\n",
        "              [0,0,0,0,0,0,0,0,0,0],\n",
        "              [0,0,0,0,0,0,0,0,0,0],\n",
        "              [0,0,0,0,0,0,0,0,0,0]],dtype=np.float32) # 입력영상 생성\n",
        "\n",
        "# 미분 필터 생성\n",
        "ux=np.array([[-1,0,1]])\n",
        "uy=np.array([-1,0,1]).transpose()\n",
        "# 가우시안 필터 생성\n",
        "k=cv.getGaussianKernel(3,1)\n",
        "g=np.outer(k,k.transpose())\n",
        "\n",
        "# dy, dx 도출\n",
        "dy=cv.filter2D(img,cv.CV_32F,uy)\n",
        "dx=cv.filter2D(img,cv.CV_32F,ux)\n",
        "\n",
        "dyy=dy*dy\n",
        "dxx=dx*dx\n",
        "dyx=dy*dx\n",
        "\n",
        "gdyy=cv.filter2D(dyy,cv.CV_32F,g)\n",
        "gdxx=cv.filter2D(dxx,cv.CV_32F,g)\n",
        "gdyx=cv.filter2D(dyx,cv.CV_32F,g)\n",
        "\n",
        "# 특징가능성 맵 도출\n",
        "C=(gdyy*gdxx-gdyx*gdyx)-0.04*(gdyy+gdxx)*(gdyy+gdxx) \n",
        "\n",
        "\n",
        "# 비최대 억제 사용\n",
        "for j in range(1,C.shape[0]-1):\t\t\n",
        "    for i in range(1,C.shape[1]-1):\n",
        "        if C[j,i]>0.1 and sum(sum(C[j,i]>C[j-1:j+2,i-1:i+2]))==8: \n",
        "          # 극점이 되려면 C가 0.1보다 커야 하며 8개 이웃보다 커야 함\n",
        "            img[j,i]=9\t\t\t# 특징점을 원본 영상에 9로 표시\n",
        "                \n",
        "# 특징 가능성 맵 C 계산하는 데 필요한 미분 영상 출력                \n",
        "np.set_printoptions(precision=2)\n",
        "print(dy) \n",
        "print(dx) \n",
        "print(dyy) \n",
        "print(dxx) \n",
        "print(dyx) \n",
        "print(gdyy) \n",
        "print(gdxx) \n",
        "print(gdyx) \n",
        "\n",
        "print(C)\t\t\t\t\t# 특징 가능성 맵 \n",
        "print(img)\t\t\t\t\t# 특징점을 9로 표시한 원본 영상 \n",
        "\n",
        "# 화소 확인 가능하게 16배로 확대해 윈도우에 보임\n",
        "popping=np.zeros([160,160],np.uint8)\t\n",
        "for j in range(0,160):\n",
        "    for i in range(0,160):\n",
        "        popping[j,i]=np.uint8((C[j//16,i//16]+0.06)*700)  \n",
        "\n",
        "cv.imshow('Image Display2',popping)    \n",
        "cv.waitKey()\n",
        "cv.destroyAllWindows()"
      ],
      "metadata": {
        "id": "ZSwjgZgIFeU1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2 as cv\n",
        "\n",
        "img=cv.imread('mot_color70.jpg') # 영상 읽기\n",
        "gray=cv.cvtColor(img,cv.COLOR_BGR2GRAY)\n",
        "\n",
        "sift=cv.SIFT_create() # SIFT 특징점 추출하는데 쓸 객체 생성\n",
        "kp,des=sift.detectAndCompute(gray,None) # 특징점, 기술자 탐색\n",
        "\n",
        "# 특징점 영상에 표시\n",
        "gray=cv.drawKeypoints(gray,kp,None,flags=cv.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
        "\n",
        "cv.imshow('sift', gray)\n",
        "\n",
        "k=cv.waitKey()\n",
        "cv.destroyAllWindows()"
      ],
      "metadata": {
        "id": "mVq6dAmuGVTK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2 as cv\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "# 물체 모델 영상 정하기\n",
        "img1=cv.imread('mot_color70.jpg')[190:350,440:560] # 버스를 크롭하여 모델 영상으로 사용\n",
        "gray1=cv.cvtColor(img1,cv.COLOR_BGR2GRAY)\n",
        "\n",
        "# 물체 장면 영상 정하기\n",
        "img2=cv.imread('mot_color83.jpg')\t\t\t     \n",
        "gray2=cv.cvtColor(img2,cv.COLOR_BGR2GRAY)\n",
        "\n",
        "sift=cv.SIFT_create()\n",
        "kp1,des1=sift.detectAndCompute(gray1,None)\n",
        "kp2,des2=sift.detectAndCompute(gray2,None)\n",
        "print('특징점 개수:',len(kp1),len(kp2)) \n",
        "\n",
        "start=time.time()\n",
        "flann_matcher=cv.DescriptorMatcher_create(cv.DescriptorMatcher_FLANNBASED) # FLANN 라이브러리 사용\n",
        "knn_match=flann_matcher.knnMatch(des1,des2,2) # 최근접 두개 찾기\n",
        "\n",
        "# 임계값 이용해 최근접 이웃거리 비율 전략 적용\n",
        "T=0.7\n",
        "good_match=[]\n",
        "for nearest1,nearest2 in knn_match:\n",
        "    if (nearest1.distance/nearest2.distance)<T:\n",
        "        good_match.append(nearest1)\n",
        "print('매칭에 걸린 시간:',time.time()-start) \n",
        "\n",
        "# 매칭 결과 보여줄 ㄹ영상 생성\n",
        "img_match=np.empty((max(img1.shape[0],img2.shape[0]),img1.shape[1]+img2.shape[1],3),dtype=np.uint8)\n",
        "cv.drawMatches(img1,kp1,img2,kp2,good_match,img_match,flags=cv.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
        "\n",
        "cv.imshow('Good Matches', img_match)\n",
        "\n",
        "k=cv.waitKey()\n",
        "cv.destroyAllWindows()"
      ],
      "metadata": {
        "id": "yFLon3BwGVQm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# good_match : 매칭 쌍 중 좋은 것을 골라 저장한 리스트\n",
        "points1=np.float32([kp1[gm.queryIdx].pt for gm in good_match]) # 첫번째 영상 특징점 좌표 \n",
        "points2=np.float32([kp2[gm.trainIdx].pt for gm in good_match]) # 두번째 영상 특징점 좌표\n",
        "\n",
        "H,_=cv.findHomography(points1,points2,cv.RANSAC) # 호모그래피 행렬 추정\n",
        "\n",
        "h1,w1=img1.shape[0],img1.shape[1] \t\t# 첫 번째 영상의 크기\n",
        "h2,w2=img2.shape[0],img2.shape[1] \t\t# 두 번째 영상의 크기\n",
        "\n",
        "box1=np.float32([[0,0],[0,h1-1],[w1-1,h1-1],[w1-1,0]]).reshape(4,1,2) # 첫번째 영상을 포함하는 네 구석의 좌표 저장\n",
        "box2=cv.perspectiveTransform(box1,H) # 첫번째 영상 좌표에 행렬 H 적용, 두번째 영상 투영한 결과 저장\n",
        "\n",
        "img2=cv.polylines(img2,[np.int32(box2)],True,(0,255,0),8) # box2를 두번째 영상에 그리기\n",
        "\n",
        "img_match=np.empty((max(h1,h2),w1+w2,3),dtype=np.uint8)\n",
        "cv.drawMatches(img1,kp1,img2,kp2,good_match,img_match,flags=cv.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
        "   \n",
        "cv.imshow('Matches and Homography',img_match)\n",
        "\n",
        "k=cv.waitKey()\n",
        "cv.destroyAllWindows()"
      ],
      "metadata": {
        "id": "VjYHjEEAGVOL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8VLWCgncGVLi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NhEerR40GVJE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fGSQXb2CGVDN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gFG3IEqtFeIt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}