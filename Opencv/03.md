# chap6 비전 에이전트

## 6.1 지능 에이전트로서 비전 에이전트

## 6.2 PyQt를 이용한 사용자 인터페이스

## 6.3 [비전에이전트1] 오림

## 6.4 [비전에이전트2] 교통약자 보호구역 알림

## 6.5 [비전에이전트3] 파노라마 영상 제작

## 6.6 [비전에이전트4] 특수 효과


# chap7 딥러닝 비전

## 7.1 방법론의 대전환

고전적 컴퓨터 비전 "규칙기반" 의 한계

사람이 면밀히 데이터를 관찰해 정교하게 알고리즘 개발 및 개선 => 수작업 특징 / 수작업 알고리즘
수작업 알고리즘 결과 => 규칙으로 표현
- 이런 규칙기반 알고리즘은 사람의 노력으로 일정 수준 달성하나, 그 이상을 돌파하기 어려움
  ex. 더 좋은 가우시안 필터는 없을까? 데이터에 따라 최적의 필터를 설계해야 하지 않을까?

<-> 현대적 컴퓨터 비전 "데이터 중심 딥러닝"(=기계학습) 은 위의 한계점 보완

![image](https://user-images.githubusercontent.com/109460178/227842783-cff65a74-d044-4540-9a84-06726ff15dac.png)

## 7.2 기계학습의 기초

![image](https://user-images.githubusercontent.com/109460178/227844480-8db16262-59df-4b21-a6ab-917d1dcb7cb8.png)


- 모델 : 기계학습에서 함수
- 학습 : 수집한 데이터로 방정식을 풀어 함수(모델)을 알아내는 일

<예측에 쓸 모델 얻는 방법>
1. 데이터 수집
  - 훈련집합 : 수집한 샘플의 모음 (보통, 샘플의 개수 : n)

2. 모델 선택
  선형과 비선형의 다양한 함수 관계 적용 가능
  
3. 학습 
  훈련 집합에 있는 n개의 샘플을 모델에 대입한 방정식 풀이 
  -> 가중치 값 도출
  -> 데이터 학습된 모델 확인

4. 예측
  훈련 집합에 없는 새로운 샘플을 대입해 예측
  ex) x=X 대입 -> 모델 기반 y 예측


##### STEP1 : 데이터 수집

![image](https://user-images.githubusercontent.com/109460178/227845947-0c42551a-c492-4f9a-a269-df15656545e7.png)


- 입력 : x 특징벡터 feature vector
        - d개의 특징으로 구성되는 벡터
        - 
- 출력 : y 참값 GT: Ground Truh or 레이블 label
        - 학습된 모델로 x에 대해 y를 계산하는 예측 문제로 y 연속된 값 => 회귀 regression
        - 입력영상에서 물체 부류를 알아내는 문제로 y 이산값 => 분류 classification
        
- 데이터셋 D : 특징 벡터(x)마다 참값(y)이 붙어 있는 n개 샘플로 구성

데이터 수집 시, 비용이 많이 듦 
분할의 경우 물체가 차지한 영역을 화소 수준으로 지정해야 하기에 노동 집약적


##### STEP2 : 모델 선택

입력가 출력의 관계가 더 복잡할수록 비선형 모델 사용
학습이 추정할 가중치가 핵심 포인트

딥러닝은 수십 개 층으로 구성되어 각 층마다 가중치 존재
가중치가 수만~수억 개인 큰 용량의 모델 사용
가중치를 매개변수라고 부르기도 함

W = {U^1, U^2, U^3,... , U^L} 
- W : 가중치 행렬
- U : 각 층의 가중치 벡터
- L : 층의 개수


##### STEP3 : 학습

훈련 집합에 있는 샘플을 **최소 오류로 맞히는 최적의 가중치 값 도출**하는 과정

- 분석적 방법 : 모델 함수에 데이터셋을 대입해 만든 방정식을 풀어 가중치 최적값 도출
- 수치적 방법 : 분석적 방법에서 발생하는 잡음, 모델 분포와 데이터 분포의 불일치 등으로 발생하는 오류를 줄이는 과정을 반복


**평균제곱오차MSE**
최적화 알고리즘 (옵티마이저 optimizer) : 평균제곱오차를 최소로하는 가중치의 최적값 도출
** 최적의 가중치 찾는 방법 = 오류를 얼마나 덜 범하는지 측정하는 함수 필요
=> 손실함수 loss function 

![image](https://user-images.githubusercontent.com/109460178/227847836-2702e4b7-e03b-4454-8803-381bef884267.png)

- 0에 가까울수록 좋음 

![image](https://user-images.githubusercontent.com/109460178/227848181-f4c3eb70-c3a3-4a26-b44e-727064861832.png)

- 검은점 : y값 <-> 직선상의 점 : 모델의 예측값
- 점선 : 오류, 예측값 - y

=> 모든 점선 길이의 제곱의 평균을 구하면 평균제곱오차
   빨간색, 파란색 모델 중 파란색 모델의 평균제공오차가 더 작아 파란색 모델이 최적

##### STEP4 : 예측

예측 : 학습을 마친 모델, 가중치의 최적값을 가진 모델에 학습 시 사용하지 않던 새로운 특징 벡터를 입력하고 출력을 구하는 과정
- 출력 구함
- 모델 성능평가

모델 성능 평가 방법 
1. 바로 현장에 설치해 정확률 측정
  -> 돈 많이 듦 
2. 데이터셋을 일정비율로 분할해 일부는 훈련 집합에 넣어 학습 사용, 나머지는 테스트 집합에 넣어 예측 사용
  -> 객관성 보장 but 데이터 셋 크기가 충분히 크지 않은 상태에서는 좋지 않을 수도.
  ex. `train_test_split(X, y, test_size = 0.4)`
      데이터를 train, test 로 60:40으로 분할
  
  ex. K-fold 교차검증
  
  ![image](https://user-images.githubusercontent.com/109460178/227849893-1b33e38a-a7be-493a-9821-ee2e83a32acb.png)

    1. 데이터 k개 분할
    2. 성능실험 k번해서 평균을 취함
    3. i = 1, 2, .., k 로 바꾸며 i번째 실험에서 i번 부분집합을 test 테이터셋으로 사용, 나머지 k-1개 부분 집합은 train 데이터 셋으로 사용
    
       

## 7.3 딥러닝 소프트웨어 맛보기

tensorflow
- 기계학습 구현을 위한 소프트웨어 도구
- tensor : 딥러닝에서 다차원배열을 이르는 말
- tesorflow 내에서 Keras 명령어로 딥러닝 개발
- https://www.tensorflow.org/datasets?hl=ko


![image](https://user-images.githubusercontent.com/109460178/227856162-5757347e-0ea0-4023-836f-98f013d62c1f.png)

(a). MNIST : 70,000개의 필기 숫자 샘플 존재 (train : 60,000 / test : 10,000 집합으로 분할되어 있음)   
     특징 벡터(x)는 숫자를 28 * 28 맵으로 표현           
     참값(y)는 숫자 부류를 나타내기 위해 0~9 사이의 값 보유           
     ex. x_train : 60000x28x28 으로 28x28 맵이 60,000장 쌓여 있는 3차원 구조          
    

(b). CIFAR-10 : 60,000개의 필기 숫자 샘플 존재 (train : 50,000 / test : 10,000 집합으로 분할되어 있음)             
     특징 벡터(x)는 숫자를 32 * 32 * 3 맵으로 표현, RGB를 위해 32x32맵이 3장 있는 구조      
     참값(y)는 숫자 부류를 나타내기 위해 0~9 사이의 값 보유           


## 7.4 인공신경망의 태동

인공 신경망 : 뉴런의 정보 처리 과정을 수학적으로 모델링한 신경망
- 사람 뇌는 단순한 연산 장치가 엄청나게 밀집된 형태로 연결된 병렬 처리기
- 
![image](https://user-images.githubusercontent.com/109460178/227862968-f4ec3618-614a-479c-b493-f3cebdb0fb10.png)

### 퍼셉트론
- 인공신경망의 구성 요소로 다수의 값을 특징벡터(x)를 입력 받아 연산을 수행하고 결과(y)를 출력층으로 내보냄
-  Perceptron은 perception과 neuron의 합성어이며 인공 뉴런

![image](https://user-images.githubusercontent.com/109460178/227864907-672ab1d4-69fd-4717-9505-95f0d07e5ddc.png)

활성함수logit는 계단함수를 사용함

![image](https://user-images.githubusercontent.com/109460178/227864858-c45e45b1-cb28-4d84-9287-9dc45903b5bf.png)

- 입력층 : d+1개의 노드
  - 특징값을 통과시키는 일만 수행해 속이 빈 원 
  - d차원의 특징 벡터를 받기 위한 d개 노드 + 1개의 바이어스 노드
  - 바이어스 노드의 역할은 딥러닝 모델의 최적화 요소이며 x0=1로 설정
  - 가중합의 크기는 편향의 크기로 조절할 수 있기에, 편향이 퍼셉트론의 출력값 y를 결정짓는 중요 변수
- 가중치 u : 입력 노드와 출력 노드를 연결하는 에지에 위치 
- s : 입력 노드값 x와 가중치 u를 곱해 얻은 바이어스 포함한 d+1개의 곱셈결과를 합함
  - 활성함수에 통과시켜 얻은 값 출력
- 출력층 : 1개 노드 
  - 연산을 수행하기 때문에 속이 찬 파란원


![image](https://user-images.githubusercontent.com/109460178/227865399-40fe328c-19d8-4f0b-bfb6-02abe2c96391.png)

![image](https://user-images.githubusercontent.com/109460178/227873388-b08430e5-a3c2-4a2e-a483-4b0cb4eb7c18.png)





## 7.5 깊은 다층 퍼셉트론

## 7.6 학습 알고리즘

## 7.7 다층 퍼셉트론 구현하기

## 7.8 [비전에이전트] 우편번호 인식기 v.1









