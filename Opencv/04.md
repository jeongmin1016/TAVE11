# Chap8. 컨볼루션 신경망
CNN : Convolutional Neural Network 합성곱 신경망      
ex. 숫자 이미지를 학습시켜 무슨 숫자인지 맞춘다거나 여러 옷 이미지 중 어떤 카테고리에 속하는 의류인지 맞추는 모델 만들 수 있음

뉴런 = 필터 = 커널

## 8.1 발상과 전개

![image](https://user-images.githubusercontent.com/109460178/229720318-25d21da9-f2fa-4a8e-bfb6-c7d445bd900e.png)

다층 퍼셉트론의 단점 : 화소의 연결성을 쓸 수 없어 개별 화소를 보고 분류할 수밖에 없어 큰 데이터셋일수록 정확도가 낮고 거의 인식하지 못함 => 완전연결층이기때문     


인간의 시신경을 모방한 기술
-> 수용장 하나는 영상의 특정 위치를 담당하며 망막에 분포한 수 많은 수용장이 영상 전체 처리하는 것 이용     

출처 : https://dotiromoook.tistory.com/20
### LeNet
1998 르쿤이 제안한 컨볼루션 신경망

![image](https://user-images.githubusercontent.com/109460178/229721504-5320d46b-784d-4df3-91b9-d72b5ab6ef4f.png)

- LeNet-1 ~ LeNet-5까지 존재
- LeNet-5는 앞선 모델보다 입력 이미지의 크기가 커져 이전 대비 디테일한 부분까지 고려해 성능 높아짐
- ImageNet이라는 방대한 데이터셋 구축


![image](https://user-images.githubusercontent.com/109460178/229721920-52713518-ef17-4fe4-a6e3-413e88ec833c.png)

- 위의 구조를 이용해 수표에 적힌 필기문자를 인식하는 시스템 개발

![image](https://user-images.githubusercontent.com/109460178/229722477-0c296ecd-203e-4b5f-ab32-58fbd978fac9.png)


## 8.2 컨볼루션 신경망의 구조
CNN :  Convolution Layer, Pooling Layer(Sub Sampling), Fully Connected Layer 를 사용하여 사람의 시각처리방식을 모방한 딥러닝 학습 모델     
목표 : 데이터에 맞는 최적의 필터를 학습하는 컨볼루션층 설계     

- convolution layer : 이미지의 특징점을 찾기 위해 사용
- pooling layer : 이미지 처리에 필요한 가중치와 연산량을 줄이기 위해 사용
- fully connected layer : 이미지 분류를 위해 사용

표준 컨볼루션 연산을 신경망에 적용하기 위해 확장 필요             
1. 필터 3차원으로 확장 : 컬러영상은 3차원 구조의 텐서이기 때문
2. 많은 필터 배치 : 풍부한 특징을 추출하기 위함

### 컨볼루션층

![image](https://user-images.githubusercontent.com/109460178/229723432-c1ba58f0-e51b-4d5d-962c-7e2dda8cb852.png)

이미지를 분류classification하는 데 필요한 특징점들feteaures 추출            
수 많은 필터가 존재하며 이 필터를 이용해 특징점 추출

<특성>
1. 가중치 공유 weight sharing    
- 필터의 값 = 가중치
- 입력 특징 맵의 모든 화소가 동일 필터를 사용해 가중치 공유
2. 부분 연결성 partial connection    
- 필터가 해당 화소 주위로 국한해 연산을 하기에 만족        

=>  두가지 특성으로 학습 알고리즘이 최적화해야 할 가중치 개수를 획기적으로 줄임
=> 필터의 개수만큼 가중치를 추정 x, k'(kh^2+1)

- 컨볼루션층은 입력특징맵(k개 채널, m*n*k모양의 3차원 텐서)에 컨볼루션을 적용해 얻은 특징feature 맵 출력       
- 필터는 하나의 바이어스 값 보유, 필터의 깊이는 입력 특징맵과 동일하게 k, 크기는 h*h (이때 h는 3 or 5)
-> 팔터는 kh^2+1개의 가중치 보유
- 필터는 깊이 방향으로는 이동하지 않고 좌우 상하 방향으로 이동하며 곱의 합 = logit 을 구하는 컨볼루션 수행
- 필터 여러개 사용하여 풍부한 특징 추출

+ padding 덧대기   
  이미지 주변에 있는 중요한 정보를 잃어버리지 않도록 방지
  입력 배열 주위를 가상의 원소로 채우는 작업
  
  맵의 경계에 필터를 대면 일부 화소가 밖으로 나가기 때문에 적용 불가 
  맵의 경계를 제외하면 층이 깊어질수록 맵의 크기 점점 작아짐              
  -> 0덧대기 / 복사 덧대기 적용
    - 0 덧대기 : 경계 바깥에 0을 덧댐
    - 복사 덧대기 : 경계 화소의  값을 복사해 덧댐
 

+ stride 보폭     
  출력 맵의 크기를 줄이는 효과    
  보폭 s로 설정하면 s 화소씩 건너 필터 적용    
  보폭이 s면 mXn맵이 (m/s)(n/s)로 감소   
  ex. stride = 2라면, 두칸씩 이동하게 되면 커널 도장을 찍는 횟수가 줄어드는 만큼 만들어지는 특성 맵의 크기는 더 작아짐

![image](https://user-images.githubusercontent.com/109460178/229998692-83b57a7e-08a5-42af-9645-5e7bb93bc308.png)

(a) 0 padding, 2 stride 설정
    5x5x3 입력특징 맵에 3x3x3 필터 2개 적용해 3x3x2 출력 특징맵 생성
    
![image](https://user-images.githubusercontent.com/109460178/229999024-38269436-b1ab-4b91-8fad-fc8db694b101.png)

+++ 제작과정 확인 : https://cs231n.github.io/convolutional-networks/
(b) 각각 필터를 적용해 구한 값(아래 식 확인)에 ReLU함수를 적용하면 출력 특징 맵 도출

![image](https://user-images.githubusercontent.com/109460178/229999093-6e8dc218-c8ec-41cd-8708-508189aa2016.png)

#### 연산량

![image](https://user-images.githubusercontent.com/109460178/230005723-2c1001a1-db00-47a7-9858-0262c0b800dc.png)

step1
- 입력 : 256x256크기의 RGB 컬러영상 = 256x256x3(깊이 k=3)
- 지정 : padding 0, stride 2, 3x3(h=3)filter(64)
- 연산량 
  + 화소 하나 당 계산 : kh^2 + 1=3x3x3 + 1=28 
  + 전체화소에 대한 필터 곱 : 화소개수 256x256, stride 2, 필터 개수 => (256/2) x (256/2) x 28 x 64
- 출력 : (256/2) x (256/2) x 64

step2
- 입력 : (128) x (128) x 64(깊이 k=64) 
- 지정 : padding 0, stride 2, 5x5(h=5)filter(128)
- 연산량 
  + 화소 하나 당 계산 : kh^2 + 1=5x5x64 + 1=1601
  + 전체화소에 대한 필터 곱 : 화소개수 128x128, stride 2, 필터 개수 => (128/2) x (128/2) x 1601 x 128
- 출력 : (128/2) x (128/2) x 128




## 8.3 컨볼루션 신경망의 학습
## 8.4 컨볼루션 신경망 구현
## 8.5 [비전 에이전트6] 우편번호 인식기 v.2
## 8.6 딥러닝의 학습 알고리즘 향상
## 8.7 전이학습
## 8.8 [비전 에이전트7] 견종 인식 프로그램

# Chap9. 인식

## 9.1 인식이란
## 9.2 분류
## 9.3 검출
## 9.4 검출
## 9.5 [비전 에이전트8] 배경을 내 맘대로 바꾸기
## 9.6 사람 인식
