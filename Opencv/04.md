# Chap8. 컨볼루션 신경망
CNN : Convolutional Neural Network 합성곱 신경망      
ex. 숫자 이미지를 학습시켜 무슨 숫자인지 맞춘다거나 여러 옷 이미지 중 어떤 카테고리에 속하는 의류인지 맞추는 모델 만들 수 있음

뉴런 = 필터 = 커널

## 8.1 발상과 전개

![image](https://user-images.githubusercontent.com/109460178/229720318-25d21da9-f2fa-4a8e-bfb6-c7d445bd900e.png)

다층 퍼셉트론의 단점 : 화소의 연결성을 쓸 수 없어 개별 화소를 보고 분류할 수밖에 없어 큰 데이터셋일수록 정확도가 낮고 거의 인식하지 못함 => 완전연결층이기때문     


인간의 시신경을 모방한 기술
-> 수용장 하나는 영상의 특정 위치를 담당하며 망막에 분포한 수 많은 수용장이 영상 전체 처리하는 것 이용     

출처 : https://dotiromoook.tistory.com/20
### LeNet
1998 르쿤이 제안한 컨볼루션 신경망

![image](https://user-images.githubusercontent.com/109460178/229721504-5320d46b-784d-4df3-91b9-d72b5ab6ef4f.png)

- LeNet-1 ~ LeNet-5까지 존재
- LeNet-5는 앞선 모델보다 입력 이미지의 크기가 커져 이전 대비 디테일한 부분까지 고려해 성능 높아짐
- ImageNet이라는 방대한 데이터셋 구축


![image](https://user-images.githubusercontent.com/109460178/229721920-52713518-ef17-4fe4-a6e3-413e88ec833c.png)

- 위의 구조를 이용해 수표에 적힌 필기문자를 인식하는 시스템 개발

![image](https://user-images.githubusercontent.com/109460178/229722477-0c296ecd-203e-4b5f-ab32-58fbd978fac9.png)


## 8.2 컨볼루션 신경망의 구조
CNN :  Convolution Layer, Pooling Layer(Sub Sampling), Fully Connected Layer 를 사용하여 사람의 시각처리방식을 모방한 딥러닝 학습 모델     
목표 : 데이터에 맞는 최적의 필터를 학습하는 컨볼루션층 설계     

- convolution layer : 이미지의 특징점을 찾기 위해 사용
- pooling layer : 이미지 처리에 필요한 가중치와 연산량을 줄이기 위해 사용
- fully connected layer : 이미지 분류를 위해 사용

표준 컨볼루션 연산을 신경망에 적용하기 위해 확장 필요             
1. 필터 3차원으로 확장 : 컬러영상은 3차원 구조의 텐서이기 때문
2. 많은 필터 배치 : 풍부한 특징을 추출하기 위함

### 컨볼루션층

![image](https://user-images.githubusercontent.com/109460178/229723432-c1ba58f0-e51b-4d5d-962c-7e2dda8cb852.png)

이미지를 분류classification하는 데 필요한 특징점들feteaures 추출            
수 많은 필터가 존재하며 이 필터를 이용해 특징점 추출

<특성>
1. 가중치 공유 weight sharing    
- 필터의 값 = 가중치
- 입력 특징 맵의 모든 화소가 동일 필터를 사용해 가중치 공유
2. 부분 연결성 partial connection    
- 필터가 해당 화소 주위로 국한해 연산을 하기에 만족        

=>  두가지 특성으로 학습 알고리즘이 최적화해야 할 가중치 개수를 획기적으로 줄임
=> 필터의 개수만큼 가중치를 추정 x, k'(kh^2+1)

- 컨볼루션층은 입력특징맵(k개 채널, m*n*k모양의 3차원 텐서)에 컨볼루션을 적용해 얻은 특징feature 맵 출력       
- 필터는 하나의 바이어스 값 보유, 필터의 깊이는 입력 특징맵과 동일하게 k, 크기는 h*h (이때 h는 3 or 5)
-> 팔터는 kh^2+1개의 가중치 보유
- 필터는 깊이 방향으로는 이동하지 않고 좌우 상하 방향으로 이동하며 곱의 합 = logit 을 구하는 컨볼루션 수행
- 필터 여러개 사용하여 풍부한 특징 추출

+ padding 덧대기   
  이미지 주변에 있는 중요한 정보를 잃어버리지 않도록 방지
  입력 배열 주위를 가상의 원소로 채우는 작업
  
  맵의 경계에 필터를 대면 일부 화소가 밖으로 나가기 때문에 적용 불가 
  맵의 경계를 제외하면 층이 깊어질수록 맵의 크기 점점 작아짐              
  -> 0덧대기 / 복사 덧대기 적용
    - 0 덧대기 : 경계 바깥에 0을 덧댐
    - 복사 덧대기 : 경계 화소의  값을 복사해 덧댐
 

+ stride 보폭     
  출력 맵의 크기를 줄이는 효과    
  보폭 s로 설정하면 s 화소씩 건너 필터 적용    
  보폭이 s면 mXn맵이 (m/s)(n/s)로 감소   
  ex. stride = 2라면, 두칸씩 이동하게 되면 커널 도장을 찍는 횟수가 줄어드는 만큼 만들어지는 특성 맵의 크기는 더 작아짐

![image](https://user-images.githubusercontent.com/109460178/229998692-83b57a7e-08a5-42af-9645-5e7bb93bc308.png)

(a) 0 padding, 2 stride 설정
    5x5x3 입력특징 맵에 3x3x3 필터 2개 적용해 3x3x2 출력 특징맵 생성
    
![image](https://user-images.githubusercontent.com/109460178/229999024-38269436-b1ab-4b91-8fad-fc8db694b101.png)

+++ 제작과정 확인 : https://cs231n.github.io/convolutional-networks/
(b) 각각 필터를 적용해 구한 값(아래 식 확인)에 ReLU함수를 적용하면 출력 특징 맵 도출

![image](https://user-images.githubusercontent.com/109460178/229999093-6e8dc218-c8ec-41cd-8708-508189aa2016.png)

#### 연산량

![image](https://user-images.githubusercontent.com/109460178/230005723-2c1001a1-db00-47a7-9858-0262c0b800dc.png)

step1
- 입력 : 256x256크기의 RGB 컬러영상 = 256x256x3(깊이 k=3)
- 지정 : padding 0, stride 2, 3x3(h=3)filter(64)
- 연산량 
  + 화소 하나 당 계산 : kh^2 + 1=3x3x3 + 1=28 
  + 전체화소에 대한 필터 곱 : 화소개수 256x256, stride 2, 필터 개수 => (256/2) x (256/2) x 28 x 64
- 출력 : (256/2) x (256/2) x 64

step2
- 입력 : (128) x (128) x 64(깊이 k=64) 
- 지정 : padding 0, stride 2, 5x5(h=5)filter(128)
- 연산량 
  + 화소 하나 당 계산 : kh^2 + 1=5x5x64 + 1=1601
  + 전체화소에 대한 필터 곱 : 화소개수 128x128, stride 2, 필터 개수 => (128/2) x (128/2) x 1601 x 128
- 출력 : (128/2) x (128/2) x 128

### 풀링층 pooling layer
이미지 처리에 필요한 가중치와 연산량을 줄이기 위해 사용
상세함을 줄이는 효과와 특징 맵의 크기를 줄여 신경망의 효율을 높이는 효과 제공

![image](https://user-images.githubusercontent.com/109460178/230006186-f41cea7a-016d-4f7b-896d-40b24506d8d7.png)

stride = 2 인 경우, max pooling(최대풀링 : 필터 안의 화소 중 최댓값을 취하는 연산)을 사용한다면 특징맵 반으로 준다 

  +) 평균 풀링 average pooling 도 존재

**빌딩블록 쌓기 = convolution layer + pooling layer + Fully Connected layer**      

![image](https://user-images.githubusercontent.com/109460178/230007944-9a7c15c4-d137-4ebe-b584-4517f8c12f49.png)

- convolution layer + pooling layer : 특징 추출 역할
- Flatten : 다차원 구조를 1차원 구조로 변환해 Fully Connected layer에 입력
- Fully Connected layer : 분류 수행

데이터에 따라 or 풀어야 하는 문제에 따라 다양한 모양으로 조립 가능
- case1) [Springenberg2014] 풀링층 모두 제거, only 컨볼루션층으로 쌓음

![image](https://user-images.githubusercontent.com/109460178/230009528-e8131e4f-a728-4223-a42f-b0ecabe1823b.png)

- case2) [Autoencoder] 입력영상을 그대로 출력영상으로 내놓는 컨볼루션 신경망
          encoder와 decoder로 구성되며 이는 대칭을 이루도록 설계
          인코더는 특징 맵을 점점 작게하고 디코더에서 다시 키워 원래 영상 복원

![image](https://user-images.githubusercontent.com/109460178/230010810-97b35831-9c0d-49b1-808e-90c568f28bd0.png)

- case3) 완전 연결층 제거해 마지막 컨볼루션층에 레이블된 분할 맵을 배치     
        영상분할을 이용한 컨볼루션 신경망

**Example : LeNet-5 **        
LeNet-5 : 세계 최초로 실용화에 성공한 컨볼루션 신경망

![image](https://user-images.githubusercontent.com/109460178/230009767-6b953d49-06fe-4888-ad09-2a235cfa5dcf.png)

- convolution : 컨볼루션층
- sub-sampling : 풀링층
- full-connection : 완전연결층
- output : 필기 숫자를 개발하였기에 출력층에 10개의 노드 존재
- 숫자맵은 명암이기에 입력 특징맵의 깊이는 1

![image](https://user-images.githubusercontent.com/109460178/230009844-3e57e304-950c-4bf3-814c-7acc68c750fd.png)

- 입력 32x32
- C conv1 : padding 0, stride 1, 5x5(h=5)filter 6
- 결과1 : 28x28x6
- P pooling1 
- 결과2 : 14x14x6

- 입력 14x14x6
- C conv2 : padding x, stride 1, 5x5(h=5)filter 16
- 결과3 : 10x10x16
- P pooling2
- 결과4 : 5x5x16

- 입력 5x5x16
- C conv3 : padding x, stride 1, 5x5(h=5)filter 120
- 결과5 : 1x1x120

- Flattern : 1차원 구조 변환 
- FC 완전연결층 : 84개 노드 
- 은닉층
- 출력층 : 10개 노드

## 8.3 컨볼루션 신경망의 학습

**역전파 알고리즘**
![image](https://user-images.githubusercontent.com/109460178/230304740-a070aaf8-fb15-4039-8a30-1021b25f7d7d.png)

(1) 전방계산 : 컨볼루션층과 풀링층, 완전연결층을 거쳐 벡터o 출력        
(2) 손실계산 : 손실함수를 통해 벡터o와 참값 벡터 y의 오류를 계산        
(3) 역전파 : 오류를 줄이는 방향으로 가중치 갱신       
  - 갱신 대상 : U^1, U^2, ... U^L-2(컨볼루션 층 위치) / U^L-1, U^L(완전연결 층 위치) => 학습대상이 되는 가중치 빨간색

가중치 행렬인 커널이 여러 번 사용되어 손실에 대한 편미분을 계산하기 까다로워 보일 수 있음       
-> 컨볼루션 연산 형태로 결과가 나오기에 이해하거나 기억하기 쉬움        
-> 단지 완전연결층과 계산이 다르기에 계산식에 따라 미분 다르게 수행


컨볼루션 신경망의 장점은 **특징추출 담당하는 필터 학습**      
CNN이 feature learning한다고 표현

![image](https://user-images.githubusercontent.com/109460178/230320940-6c62344e-fb4f-4f79-95cd-a1f5b7b99e4a.png)

**장점**
1. 데이터의 원래 구조 유지
2. 특징학습을 통해 최적의 특징 추출
3. 신경망의 깊이 파악 가능

## 8.4 컨볼루션 신경망 구현
`cnn.add(Conv2D(6,(5,5),padding='same',activation='relu',input_shape=(28,28,1)))`         
add함수와 Conv2D를 이용해 cnn 객체에 컨볼루션층 추가      
- (1,2) 5x5 필터 6개 
- (3) 0 패딩 <-> `padding='valid'` : 덧대기x
- 활성화함수
- 최초로 입력되는 텐서 모양 지정

`cnn.add(MaxPooling2D(pool_size=(2,2),strides=2))`       
- (2,2) 필터
- 보폭2

> 결과
![image](https://user-images.githubusercontent.com/109460178/230324969-cce0fed2-77c4-4091-a1eb-e9a0fbb3d4f7.png)

![image](https://user-images.githubusercontent.com/109460178/230325022-23fd4d8e-62d9-49d4-9477-9cfe25aa4800.png)

> 결과
과잉적합이 방지된 형태 

![image](https://user-images.githubusercontent.com/109460178/230327944-bffbe8d3-0e2e-407d-9682-bc89f7f4a5b8.png)

-------------------------------------------------     
텐서플로 모델 구축을 위해 필요한 모듈 

**models** : 딥러닝 모델 구축을 위해 모델 생성할 때 사용             
= 종류 
- Sequential : 한 갈래 텐서가 끝까지 흐름
- Functional API : 중간에 여러 갈래로 나뉨

**layers** : 층 쌓을 때 사용        
= 종류 
- Dense 완전연결층
- Conv2D 컨볼루션층
- MaxPooling2D 최대풀링
- Flattern 특징맵 1차원 구조로 변경
- Dropout 드롭아웃 규제 
추가로 필터의 방향에 따라 구조가 항상 컨볼루션층을 결정할 필요 없음
  ex. 필터가 3차원 구조여도 conv2d적용 -> 컨볼루션 연산에서 필터가 깊이 방향으로 이동하지 않고 수평 수직 방향으로 이동하기 때문        

**losses** : 손실함수 지정할 때 사용         
- MSE Mean Squared Error
- 교차 엔트로피 cross entropy

**optimizers** : 옵티마이저 지정할 때 사용    
- SGD
- Adam


## 8.5 [비전 에이전트6] 우편번호 인식기 v.2
## 8.6 딥러닝의 학습 알고리즘 향상
## 8.7 전이학습
## 8.8 [비전 에이전트7] 견종 인식 프로그램

# Chap9. 인식

## 9.1 인식이란
## 9.2 분류
## 9.3 검출
## 9.4 검출
## 9.5 [비전 에이전트8] 배경을 내 맘대로 바꾸기
## 9.6 사람 인식
